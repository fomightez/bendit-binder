{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to accessing and reviewing the bendit results\n",
    "\n",
    "Potentially, a lot of data can be generated when the demo pipeline is run, and steps were taken to make handling all that as easy as possible. However, accessing that collected data may not be obvious to the uninitiated. This notebook covers what the 'realistic' pipeline [here](index.ipynb) produces and how to access it. Furthermore, it touches on how to use Jupyter/Python to conveniently view and further process all the data.\n",
    "\n",
    "The hope is this covers what is necessary to use the generated output. Therefore, if you just plugged your sequences into the demo pipeline, you should be able to follow along to get the bendIt results for all you data. If you are looking to adapt the pipeline, this notebook will give you a flavor of the types of output you may wish to gather or not include your adapted bendIt pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the bendIt results: Starting up an active session\n",
    "\n",
    "If you already have an active Jupyter session going, you can skip this step.\n",
    "\n",
    "However, if you have a previously saved result from the demo pipeline and you are now returning to it and looking to access the contents of the archive, the best way to get started is to start a session by going [here](https://github.com/fomightez/bendit-binder) and clicking on the `launch bend.it` badge. When the session starts, select the `Accessing_and_reviewing_the_bendit_results.ipynb` notebook from the navigation panel at the right and work through the steps below this.\n",
    "\n",
    "The uncompressing step below should work on an unix-style command line. However, some of the advanced steps under the section entitled 'Using Python to review the data or customize the plots' involve modules/packages that aren't necessarily in a standard Python installation. By running in the recommended environment as directed above, the code is more likely to work without hiccups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the bendIt results: Uncompress the Archive\n",
    "\n",
    "This notebook assumes, you just ran the pipeline and are trying to access the results. There is then a number of files in the current directory beside the archive. To make things easier, I am going to suggest making a new directory with a simple name and then you could drag the archive into that folder and work there. To make things match witih the demo, I am going to write out those steps as commands, too. Feel free to run the cells or to do it by hand. If you make a different 'unpack' directory, you'll need to adjust things below accordingly.\n",
    "\n",
    "The exclamation marks in front of the shell commands, tells Jupyter to run those commands as shell commands and not Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir unpack\n",
    "!mv bendit_analysis*.tar.gz unpack/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things in this notebook work, you'll need to switch the current working directory over to where we are going to unpack the archive. We'll use the Jupyter magic command `%cd` to change the working directory for all subsequent cells in the notebook. If we just used `!cd`, it would only change the directory for that cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/unpack\n"
     ]
    }
   ],
   "source": [
    "%cd unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you can check anytime what is the current working directory with `pwd`. (Note most shell commands need an exclamation point but a few were added in to Jupyter so they work without it and `pwd` is one.) Also of note, is that this location is completely independent of where the file navigation pane on the left side of this window may be showing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/unpack'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **unpack the archive**, we'll run the command in the following cell.  \n",
    "You need to edit the command so it will extract your file. In other words, the part after the `xzf` has to be changed to match the actual file name of the archive you are working with in particular.\n",
    "\n",
    "(Note that I am keeping this untarring step as generic as possible so that it would work as written on any unix-style command line without the exclamation point.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf bendit_analysisFeb2020202219.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the above cell and saw anything like `tar (child): bendit_analysisZZZZZZ.tar.gz: Cannot open: No such file or directory`, it simply means you had the file name wrong. You'll need to edit it and run the cell again.\n",
    "\n",
    "If things worked, you should just see the asterisk to the left of the cell turn to a number. If you changed the file navigation pane on the left-side of this browser window over to the 'unpack' directory, after a moment you should see more files show up in the file pane. Don't worry if you didn't switch. We are going to explore the contents using commands next anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Unpacked Items\n",
    "\n",
    "If all is correct and you used the `%cd` command to previously switch to the 'unpack directory, running the next cell will show the contents of the current working directory so we can begin to explore the contents of the-now-unpacked archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.3M\n",
      "-rw-r--r-- 1 jovyan root  11K Feb 20 22:18 A_output.png\n",
      "-rw-r--r-- 1 jovyan root 365K Feb 21 18:47 bendit_analysisFeb2020202219.tar.gz\n",
      "-rw-r--r-- 1 jovyan root  10K Feb 20 22:18 B_output.png\n",
      "-rw-r--r-- 1 jovyan root 3.1K Feb 20 22:18 demo_A.pkl\n",
      "-rw-r--r-- 1 jovyan root  38K Feb 20 22:18 demo_A.png\n",
      "-rw-r--r-- 1 jovyan root  43K Feb 20 22:18 demo_A.svg\n",
      "-rw-r--r-- 1 jovyan root 1.6K Feb 20 22:18 demo_A.tsv\n",
      "-rw-r--r-- 1 jovyan root 3.1K Feb 20 22:19 demo_B.pkl\n",
      "-rw-r--r-- 1 jovyan root  38K Feb 20 22:19 demo_B.png\n",
      "-rw-r--r-- 1 jovyan root  44K Feb 20 22:19 demo_B.svg\n",
      "-rw-r--r-- 1 jovyan root 1.6K Feb 20 22:19 demo_B.tsv\n",
      "-rw-r--r-- 1 jovyan root 1.3K Feb 20 22:19 demo_cassettesGC.pkl\n",
      "-rw-r--r-- 1 jovyan root  166 Feb 20 22:19 demo_cassettesGC.tsv\n",
      "-rw-r--r-- 1 jovyan root 1.1K Feb 20 22:19 demo_mergedGC.pkl\n",
      "-rw-r--r-- 1 jovyan root  110 Feb 20 22:19 demo_mergedGC.tsv\n",
      "-rw-r--r-- 1 jovyan root   65 Feb 20 22:18 demo_sample_set.fa\n",
      "-rw-r--r-- 1 jovyan root 5.0K Feb 20 22:19 LOG_baFeb2020202219.txt\n",
      "-rw-r--r-- 1 jovyan root 100K Feb 20 22:19 plots4review_from-baFeb2020202219.ipynb\n",
      "-rw-r--r-- 1 jovyan root 544K Feb 20 22:19 seqs_dfs_and_plots_for_each_set.pkl\n"
     ]
    }
   ],
   "source": [
    "ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That lists out the contents of the directory. The options added along with the `ls` command make the output more redable by showing. In particular, the `h` in `-lh` means the file sizes are human readable and the `l` in `-lh` says to list the details in long form and not just the names.\n",
    "\n",
    "You'll see there is much more than the compressed archive that was originally added when we made the directory just a few cells back. These are the results of the bendIt run. The following section will go through what these are and how to use them.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used your own data, your results will be different but the types will be the same.  I am going describe the contents as if you ran the demo sequences; however, mostly you just need to pay attention to the file extensions, or sometimes the start of the name, to tell which file types correspond.\n",
    "\n",
    "After a brief overview, I am going to add some details about most of the types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical contents overview:\n",
    "\n",
    "- Log file\n",
    "- Image files for the plots\n",
    "- a notebook for reviewing all the plots en masse\n",
    "- serialized (pickeled) bendIt data \n",
    "- bendIt data as tabular text\n",
    "- Nucleotide composition detail\n",
    "- serialized processing information and results on a per sample basis\n",
    "- input files\n",
    "- raw gnuplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log file\n",
    "\n",
    "The Log file will look something like `LOG_ba<MONTH>ZZZZZZZZZ.txt` with the `<MONTH>` showing the abbreviation for the month and the `ZZZZZZZZ` portion being derived from a time date stamp.\n",
    "\n",
    "This contains much of what was shown as the demo pipeline ran with some additional details from the actualy bendIt job(s) for each sequence.\n",
    "\n",
    "At the end is a summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image files for the plots\n",
    "\n",
    "The plots have been saved a two forms of images. The first part of the name of each is derived from the sample_set name and the individual sample name. The two extensions delineate them:\n",
    "\n",
    "- `.png`  \n",
    "Examples from the demo input `demo_A.png` and `demo_B.png`.   \n",
    "This is a raster/bitmap file format made of pixels that you are probably familair with. While it is great for viewing easily as a lot of software, including JupyterLab, can handle it, please see the note below suggesting `.svg` for scaling up, or the Python section that discusess making individual plots larger and making new image files in `.png` format from that.\n",
    "\n",
    "- `.svg`  \n",
    "Examples from the demo input `demo_A.svg` and `demo_B.svg`.    \n",
    "This indicates SVG (scalable vector grpahics) file format. SVG is really the best choice for scaling up or adapting further as it offers the most control and no less of resolution. Sugggest using Adobe Illustrator or Inkscape for scaling and customizing. This is what you'll want to use if you don't want to remake the plot and are looking to customize it for publication. Any modern browser can view `.svg` files, and fortunately an SVG viewer is built right into JupyterLab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook for reviewing all the plots en masse\n",
    "\n",
    "The file name for this file will resemble `plots4review_from-ba<MONTH>ZZZZZZZZ.ipynb` with the time data stamp matching the arhive file name and log file name.\n",
    "\n",
    "The image files dsicussed above are nice but not that easy to view unless you bring them local and use your file browser. Alternatively, you can browser them right in the session by opening this notebook and then opening subsequent views of it. (**ADD MORE DETAILS ON HOW TO OPEN MULTIPLE VIEW AND ADD IMAGE EXAMPLE**)\n",
    "\n",
    "At the top of this notebook, I emphasized you'll want to be in an active notebook session for working with the output. One of the main reasons is that it offers a standard environment where the archive can be unpacked easily and Jupyter offers nice viewers for many of the data types. This is the case for the 'Review' notebook. The plots are already part of the notebook and so nothing has be run again, but a Jupyter environment is useful for viewing it. Alternatively, nbviewer can be used to view a 'static' from of the notebook if you don't mind placing the notebook file somewhere [the online nbviewer](https://nbviewer.jupyter.org/) can be pointed at it. Note the static form will look much like it does in Jupyter but you cannot modify or run any cells, or modify the text content further.\n",
    "\n",
    "Note that the sample names on the plots should look like the original input sample names but might not match sample names seen in the 'serialized processing information and results on a per sample basis' file, `seqs_dfs_and_plots_for_each_set.pkl`. This is because certain characters can an issue with the processing steps and were eliminated from the sample names for processing. In the plot representations, efforts were made to substitute back in names matching a pattern used by a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialized (pickled) bendIt data\n",
    "\n",
    "This will resemble files looking like `demo_A.pkl`.\n",
    "\n",
    "The data plotted from tbe bendIt analysis is stored in a compressed form that can easily be read back in as a Pandas dataframe for convenient use in the Jupyter environment or further analysis. Acessing these Pandas dataframes in the Jupter environment will be discussed below as part of the 'Using Python to review the data or customize the plots' section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bendIt data as tabular text\n",
    "\n",
    "This will resemble files looking like `demo_A.tsv`.\n",
    "\n",
    "The data plotted from tbe bendIt analysis is stored in a tab-delimited tabular text form that can easily be used anywhere, even in Excel. Jupyter allows easy viewing of these as well. You can click on the 'frame' symbol next to the file name in the file navigto panel on the left, and they'll open as full-featured spreadsheet-like views. If you right click, and select `Open with ...` > `editor`, you can see the text form that underlies it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nucleotide composition detail\n",
    "\n",
    "These files will look like sample set names followed by `_cassettesGC.pkl` and `_cassettesGC.tsv` for the cassette sequences and  sample set names followed by `_mergedGC.pkl` and `_mergedGC.tsv for the sequences of the combined cassette sequences merged with the defined flanking sequences. \n",
    "\n",
    "The examples from the demonstration data are:\n",
    "\n",
    "- `demo_cassettesGC.pkl`\n",
    "- `demo_cassettesGC.tsv`\n",
    "- `demo_mergedGC.pkl`\n",
    "- `demo_mergedGC.tsv`\n",
    "\n",
    "These provide a breakdown of nucleotide composition and %G+C for every cassette sequence. In the serilaized (pickeled) data, it is dataframe with each sample as a row. In the tabular text data, it is a tab-separated file with each sample as a row. The rank of %G+C from lowest to highest is the final column.\n",
    "\n",
    "Similar data is provided for every merged sequence where cassette flanked by the defined sequences.\n",
    "\n",
    "Accessing the tabular text is similar to what is described under 'bendIt data as tabular text'.\n",
    "\n",
    "Accessing the serialized Pandas dataframes in the Jupter environemnt will be discussed below as part of the 'Using Python to review the data or customize the plots' section.\n",
    "\n",
    "The source dataframes are also included in the 'serialized processing information and results on a per sample basis' file, `seqs_dfs_and_plots_for_each_set.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialized processing information and results on a per sample basis\n",
    "\n",
    "This file will be named `seqs_dfs_and_plots_for_each_set.pkl`.\n",
    "\n",
    "This is almost all the input sequences and output stored on a per sample set and per sample basis using Pyton dictionaries. This is mainly meant for advanced use. It actually gets used in the top of the `Notebook for reviewing all the plots en masse` to render all the plots. It will be used to access the dataframes as well as an example below. Really beyond being used to easily render all the plots, it is really just there to have it in case something not collected here is necessary or needs to be checked. \n",
    "\n",
    "In the `seqs_dfs_and_plots_for_each_set.pkl`, there is a value for each sample set. That value is a list of dictionaries. The order of the list dictionaries for each sample set is as follows:\n",
    "\n",
    "- cassette sequences processed keyed on name\n",
    "- sequences of the cassette sequences merged to the defined flanking sequences processed keyed on name\n",
    "- breakdown of nucleotide composition and %G+C for every cassette sequence (dataframe with each sample as a row)\n",
    "- breakdown of nucleotide composition and %G+C for every merged sequence where cassette flanked by the defined sequences (dataframe with each sample as a row)\n",
    "- dataframes produced by bendIt analysis & used to make the plots keyed by sample\n",
    "- plots produced from each dataframe keyed by sample\n",
    "\n",
    "As the information is stored serialized (pickled), it has to be unpickled first. The following code can be used to do unpickle and bring it into an active Jupyter notebook namespace:\n",
    "\n",
    "```python\n",
    "with open(seqs_dfs_and_plots_for_each_set.pkl, \"rb\") as f:\n",
    "    seqs_dfs_and_plots_per_sample_set = pickle.load(f)\n",
    "```\n",
    "\n",
    "You'll note that this code gets used in the notebook for reviewing the plots en masse as it is from this source that the plots were added to the review notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files\n",
    "\n",
    "The sequence files of the cassette sequences were stored in FASTA format in the archive as well in order to provide a more an intact artifact of all stages of the run.\n",
    "\n",
    "As they are in FASTA format, they'll most likely end in `.fa` or `.fasta`.\n",
    "\n",
    "The input files may also exist in sanitized and unsanitized form if the sample names included characters that would have caused issues in the processing steps.\n",
    "\n",
    "### Raw gnuplots\n",
    "\n",
    "These files will look like sample names followed by `_output.png`.\n",
    "\n",
    "The raw gnuplots made by bendIt for each sample were saved. Overall these should resemble the plots generated for each cassette merged into the flanking sequences analyzed and are only meant for verification of that and troubleshooting. Keep in mind that for short sequences, the right side of the gnuplot will not represent the correct form as extra sequences were added to avoid a segmentation fault when bendIt was run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Using Python to review the data or customize the plots\n",
    "\n",
    "A number of options readily exist for using and further processing the unpacked data. This section illustrates some of those. A good portion at the end focuses on accessing the data in the 'serialized processing information and results on a per sample basis' file, `seqs_dfs_and_plots_for_each_set.pkl`. That portion is probably best considered 'advanced' as it requires more understanding of Python syntax to fully understand what is going. Most of the other examples only require name changes to get to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing dataframes for the plotted data\n",
    "\n",
    "While JupyterLab adds big improvements for viewing the CSVs/TSVs derived from (or which can be the source of) such dataframes, viewing and handling the dataframes within Jupyter is going to come up. Jupyter is particularly good at rendering Pandas dataframes nicely. \n",
    "\n",
    "This section will describe accessing the serialized (pickled) bendIt data in files looking like `demo_A.pkl`. This is mainly to serves as an introduction to illustrate the process and handling dataframes. \n",
    "\n",
    "If you are looking to use the bendIt data that is actually plotted elsewhere, you'd probably want what is described above as 'bendIt data as tabular text' which is in the files looking like `demo_A.tsv`. Where there sample set and sample names are in te file. The dataframe form is nice if you are continuing on with using Python to examine.\n",
    "\n",
    "Let's illustrate viewing a dataframe in Jupyter by bringing the serialized form in.\n",
    "\n",
    "It would be fairly easy to bring in the TSV form to a dataframe as well, but the serialized just needs to be read in at this point.\n",
    "\n",
    "As the command shows in the next cell, we can just put the file name of the serialized dataframe in a command like `df = df.read_pickle('demo_A.pkl')` where you'd replace `demo_A.pkl` with your file name of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('demo_A.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a representation of the dataframe, we can call it now since we defined it as `df` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Predicted_curvature</th>\n",
       "      <th>Bendability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>8.9765</td>\n",
       "      <td>6.1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>g</td>\n",
       "      <td>9.2796</td>\n",
       "      <td>6.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>79</td>\n",
       "      <td>a</td>\n",
       "      <td>6.8233</td>\n",
       "      <td>5.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>80</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>81</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>82</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>83</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Position Sequence  Predicted_curvature  Bendability\n",
       "0          3        a               0.0000       0.0633\n",
       "1          4        a               0.0000       1.3522\n",
       "2          5        a               0.0000       3.9733\n",
       "3          6        c               8.9765       6.1887\n",
       "4          7        g               9.2796       6.2942\n",
       "..       ...      ...                  ...          ...\n",
       "76        79        a               6.8233       5.9429\n",
       "77        80        g               0.0000       6.8829\n",
       "78        81        c               0.0000       6.8913\n",
       "79        82        t               0.0000       6.1950\n",
       "80        83        g               0.0000       0.0000\n",
       "\n",
       "[81 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just look at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Predicted_curvature</th>\n",
       "      <th>Bendability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>c</td>\n",
       "      <td>8.9765</td>\n",
       "      <td>6.1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>g</td>\n",
       "      <td>9.2796</td>\n",
       "      <td>6.2942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position Sequence  Predicted_curvature  Bendability\n",
       "0         3        a               0.0000       0.0633\n",
       "1         4        a               0.0000       1.3522\n",
       "2         5        a               0.0000       3.9733\n",
       "3         6        c               8.9765       6.1887\n",
       "4         7        g               9.2796       6.2942"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or look at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Predicted_curvature</th>\n",
       "      <th>Bendability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>79</td>\n",
       "      <td>a</td>\n",
       "      <td>6.8233</td>\n",
       "      <td>5.9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>80</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>81</td>\n",
       "      <td>c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>82</td>\n",
       "      <td>t</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>83</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Position Sequence  Predicted_curvature  Bendability\n",
       "76        79        a               6.8233       5.9429\n",
       "77        80        g               0.0000       6.8829\n",
       "78        81        c               0.0000       6.8913\n",
       "79        82        t               0.0000       6.1950\n",
       "80        83        g               0.0000       0.0000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or easily view an overview of the data contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Predicted_curvature</th>\n",
       "      <th>Bendability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.651504</td>\n",
       "      <td>5.332964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.526581</td>\n",
       "      <td>2.100518</td>\n",
       "      <td>1.584404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.476700</td>\n",
       "      <td>4.875700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>3.351800</td>\n",
       "      <td>5.416200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.963900</td>\n",
       "      <td>6.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>9.279600</td>\n",
       "      <td>9.082300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Position  Predicted_curvature  Bendability\n",
       "count  81.000000            81.000000    81.000000\n",
       "mean   43.000000             3.651504     5.332964\n",
       "std    23.526581             2.100518     1.584404\n",
       "min     3.000000             0.000000     0.000000\n",
       "25%    23.000000             2.476700     4.875700\n",
       "50%    43.000000             3.351800     5.416200\n",
       "75%    63.000000             4.963900     6.195000\n",
       "max    83.000000             9.279600     9.082300"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I include a more detailed introduction to dataframes [here](https://nbviewer.jupyter.org/github/fomightez/blast-binder/blob/master/notebooks/BLAST%20on%20Command%20Line%20and%20Integrating%20with%20Python.ipynb#Demonstrating-the-Utility-of-Having-the-BLAST-Results-in-Python) and [here](https://nbviewer.jupyter.org/github/fomightez/ptmbr-accompmatz/blob/master/notebooks/PatMatch%20with%20Python%20basics.ipynb#Demonstrating-the-Utility-of-Having-the-PatMatch-Data-in-Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Include in Python section that discusess making individual plots larger and making new image files in `.png` format from that. Though recommend `svg` as better.)\n",
    "\n",
    "also include using `.pkl` to directly get a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how to make the plots again? <=== so maybe make a utility script that is just the plotting part? <=== better way to modularize since could still change plotting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in addition to the direct pickled dataframes, show how to get to the ones keyed on sample set and samples as well as a furter illustration of the use of `seqs_dfs_and_plots_for_each_set.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ece0737a9832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mexecuteSomething\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-ece0737a9832>\u001b[0m in \u001b[0;36mexecuteSomething\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#60 seconds times 8 minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
